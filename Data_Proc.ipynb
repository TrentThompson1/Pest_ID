{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "385ae504-ba6b-4fcf-8d8c-9d1d4244e6f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T17:35:51.394255Z",
     "start_time": "2025-10-16T17:35:51.379253Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 05:35:58.205589: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-21 05:35:58.205819: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-21 05:35:58.233285: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-21 05:35:58.807562: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-21 05:35:58.807825: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetV2S # prot err\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b1627cf-6b7a-4216-8662-eb75f267de76",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-10-16T17:35:53.171359Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4395 images belonging to 12 classes.\n",
      "Found 1099 images belonging to 12 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761039380.614795  107090 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1761039380.624025  107090 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/nicholaswk/Pest_ID/efficientnet_env/lib/python3.13/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 499ms/step - accuracy: 0.1122 - loss: 2.4575 - val_accuracy: 0.1237 - val_loss: 2.4245\n",
      "Epoch 2/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 479ms/step - accuracy: 0.1363 - loss: 2.4168 - val_accuracy: 0.1729 - val_loss: 2.4022\n",
      "Epoch 3/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 480ms/step - accuracy: 0.1666 - loss: 2.3949 - val_accuracy: 0.2075 - val_loss: 2.3791\n",
      "Epoch 4/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 478ms/step - accuracy: 0.1754 - loss: 2.3760 - val_accuracy: 0.1811 - val_loss: 2.3641\n",
      "Epoch 5/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.1832 - loss: 2.3610 - val_accuracy: 0.1847 - val_loss: 2.3410\n",
      "Epoch 6/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.1836 - loss: 2.3530 - val_accuracy: 0.2266 - val_loss: 2.3271\n",
      "Epoch 7/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.1948 - loss: 2.3422 - val_accuracy: 0.2129 - val_loss: 2.3114\n",
      "Epoch 8/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 501ms/step - accuracy: 0.1950 - loss: 2.3358 - val_accuracy: 0.2002 - val_loss: 2.3155\n",
      "Epoch 9/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 472ms/step - accuracy: 0.2073 - loss: 2.3137 - val_accuracy: 0.2475 - val_loss: 2.2902\n",
      "Epoch 10/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2082 - loss: 2.3140 - val_accuracy: 0.2157 - val_loss: 2.3000\n",
      "Epoch 11/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2064 - loss: 2.3077 - val_accuracy: 0.2375 - val_loss: 2.2825\n",
      "Epoch 12/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2116 - loss: 2.2990 - val_accuracy: 0.2311 - val_loss: 2.2838\n",
      "Epoch 13/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2189 - loss: 2.2933 - val_accuracy: 0.2302 - val_loss: 2.2732\n",
      "Epoch 14/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2146 - loss: 2.2862 - val_accuracy: 0.2475 - val_loss: 2.2667\n",
      "Epoch 15/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2239 - loss: 2.2761 - val_accuracy: 0.2448 - val_loss: 2.2532\n",
      "Epoch 16/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 473ms/step - accuracy: 0.2225 - loss: 2.2915 - val_accuracy: 0.2429 - val_loss: 2.2493\n",
      "Epoch 17/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2146 - loss: 2.2851 - val_accuracy: 0.2530 - val_loss: 2.2544\n",
      "Epoch 18/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2212 - loss: 2.2747 - val_accuracy: 0.2684 - val_loss: 2.2390\n",
      "Epoch 19/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2257 - loss: 2.2611 - val_accuracy: 0.2584 - val_loss: 2.2362\n",
      "Epoch 20/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 472ms/step - accuracy: 0.2250 - loss: 2.2613 - val_accuracy: 0.2539 - val_loss: 2.2454\n",
      "Epoch 21/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2314 - loss: 2.2585 - val_accuracy: 0.2484 - val_loss: 2.2343\n",
      "Epoch 22/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2319 - loss: 2.2534 - val_accuracy: 0.2566 - val_loss: 2.2200\n",
      "Epoch 23/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2300 - loss: 2.2501 - val_accuracy: 0.2757 - val_loss: 2.2270\n",
      "Epoch 24/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2344 - loss: 2.2467 - val_accuracy: 0.2439 - val_loss: 2.2269\n",
      "Epoch 25/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 475ms/step - accuracy: 0.2430 - loss: 2.2426 - val_accuracy: 0.2693 - val_loss: 2.2144\n",
      "Epoch 26/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2375 - loss: 2.2374 - val_accuracy: 0.2193 - val_loss: 2.2282\n",
      "Epoch 27/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2378 - loss: 2.2436 - val_accuracy: 0.2584 - val_loss: 2.2082\n",
      "Epoch 28/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2382 - loss: 2.2390 - val_accuracy: 0.2712 - val_loss: 2.2146\n",
      "Epoch 29/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2400 - loss: 2.2298 - val_accuracy: 0.2675 - val_loss: 2.2018\n",
      "Epoch 30/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2309 - loss: 2.2361 - val_accuracy: 0.2812 - val_loss: 2.2060\n",
      "Epoch 31/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2514 - loss: 2.2244 - val_accuracy: 0.2402 - val_loss: 2.2028\n",
      "Epoch 32/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2455 - loss: 2.2136 - val_accuracy: 0.2766 - val_loss: 2.1956\n",
      "Epoch 33/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2455 - loss: 2.2166 - val_accuracy: 0.2875 - val_loss: 2.1831\n",
      "Epoch 34/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2476 - loss: 2.2107 - val_accuracy: 0.2812 - val_loss: 2.1930\n",
      "Epoch 35/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 472ms/step - accuracy: 0.2398 - loss: 2.2295 - val_accuracy: 0.2930 - val_loss: 2.1827\n",
      "Epoch 36/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2466 - loss: 2.2126 - val_accuracy: 0.2830 - val_loss: 2.1917\n",
      "Epoch 37/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2501 - loss: 2.2007 - val_accuracy: 0.2757 - val_loss: 2.1828\n",
      "Epoch 38/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2466 - loss: 2.2087 - val_accuracy: 0.2520 - val_loss: 2.1944\n",
      "Epoch 39/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2521 - loss: 2.2085 - val_accuracy: 0.2621 - val_loss: 2.1810\n",
      "Epoch 40/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 501ms/step - accuracy: 0.2537 - loss: 2.2009 - val_accuracy: 0.2757 - val_loss: 2.1777\n",
      "Epoch 41/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2528 - loss: 2.2106 - val_accuracy: 0.3021 - val_loss: 2.1746\n",
      "Epoch 42/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2487 - loss: 2.2009 - val_accuracy: 0.2721 - val_loss: 2.1906\n",
      "Epoch 43/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 476ms/step - accuracy: 0.2485 - loss: 2.2018 - val_accuracy: 0.2866 - val_loss: 2.1749\n",
      "Epoch 44/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 470ms/step - accuracy: 0.2555 - loss: 2.2089 - val_accuracy: 0.2639 - val_loss: 2.1792\n",
      "Epoch 45/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2532 - loss: 2.2011 - val_accuracy: 0.2939 - val_loss: 2.1706\n",
      "Epoch 46/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 471ms/step - accuracy: 0.2548 - loss: 2.2003 - val_accuracy: 0.2666 - val_loss: 2.1695\n",
      "Epoch 47/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2617 - loss: 2.1796 - val_accuracy: 0.2857 - val_loss: 2.1700\n",
      "Epoch 48/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 473ms/step - accuracy: 0.2555 - loss: 2.1924 - val_accuracy: 0.2821 - val_loss: 2.1672\n",
      "Epoch 49/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 469ms/step - accuracy: 0.2451 - loss: 2.1997 - val_accuracy: 0.2857 - val_loss: 2.1661\n",
      "Epoch 50/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2516 - loss: 2.1944 - val_accuracy: 0.2757 - val_loss: 2.1710\n",
      "Epoch 51/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2621 - loss: 2.1825 - val_accuracy: 0.2975 - val_loss: 2.1587\n",
      "Epoch 52/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2637 - loss: 2.1755 - val_accuracy: 0.3094 - val_loss: 2.1458\n",
      "Epoch 53/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2667 - loss: 2.1762 - val_accuracy: 0.2903 - val_loss: 2.1542\n",
      "Epoch 54/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2667 - loss: 2.1737 - val_accuracy: 0.2730 - val_loss: 2.1621\n",
      "Epoch 55/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2605 - loss: 2.1736 - val_accuracy: 0.2912 - val_loss: 2.1762\n",
      "Epoch 56/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2569 - loss: 2.1748 - val_accuracy: 0.2812 - val_loss: 2.1640\n",
      "Epoch 57/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2551 - loss: 2.1821 - val_accuracy: 0.2857 - val_loss: 2.1493\n",
      "Epoch 58/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2537 - loss: 2.1916 - val_accuracy: 0.2921 - val_loss: 2.1602\n",
      "Epoch 59/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2610 - loss: 2.1649 - val_accuracy: 0.2921 - val_loss: 2.1399\n",
      "Epoch 60/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 471ms/step - accuracy: 0.2637 - loss: 2.1734 - val_accuracy: 0.2966 - val_loss: 2.1424\n",
      "Epoch 61/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 472ms/step - accuracy: 0.2628 - loss: 2.1729 - val_accuracy: 0.2821 - val_loss: 2.1521\n",
      "Epoch 62/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2628 - loss: 2.1624 - val_accuracy: 0.2903 - val_loss: 2.1414\n",
      "Epoch 63/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2603 - loss: 2.1704 - val_accuracy: 0.2948 - val_loss: 2.1356\n",
      "Epoch 64/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2703 - loss: 2.1622 - val_accuracy: 0.3139 - val_loss: 2.1277\n",
      "Epoch 65/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 472ms/step - accuracy: 0.2580 - loss: 2.1705 - val_accuracy: 0.3030 - val_loss: 2.1413\n",
      "Epoch 66/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2676 - loss: 2.1615 - val_accuracy: 0.2857 - val_loss: 2.1501\n",
      "Epoch 67/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2658 - loss: 2.1600 - val_accuracy: 0.3085 - val_loss: 2.1313\n",
      "Epoch 68/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2699 - loss: 2.1615 - val_accuracy: 0.2839 - val_loss: 2.1443\n",
      "Epoch 69/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2532 - loss: 2.1733 - val_accuracy: 0.2830 - val_loss: 2.1375\n",
      "Epoch 70/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2737 - loss: 2.1527 - val_accuracy: 0.2821 - val_loss: 2.1629\n",
      "Epoch 71/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2612 - loss: 2.1688 - val_accuracy: 0.3003 - val_loss: 2.1383\n",
      "Epoch 72/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2646 - loss: 2.1608 - val_accuracy: 0.2721 - val_loss: 2.1359\n",
      "Epoch 73/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2833 - loss: 2.1454 - val_accuracy: 0.2921 - val_loss: 2.1398\n",
      "Epoch 74/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 480ms/step - accuracy: 0.2694 - loss: 2.1545 - val_accuracy: 0.2702 - val_loss: 2.1392\n",
      "Epoch 75/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2664 - loss: 2.1518 - val_accuracy: 0.2921 - val_loss: 2.1370\n",
      "Epoch 76/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 473ms/step - accuracy: 0.2696 - loss: 2.1625 - val_accuracy: 0.2821 - val_loss: 2.1421\n",
      "Epoch 77/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2592 - loss: 2.1695 - val_accuracy: 0.2966 - val_loss: 2.1222\n",
      "Epoch 78/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2623 - loss: 2.1551 - val_accuracy: 0.3003 - val_loss: 2.1310\n",
      "Epoch 79/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 499ms/step - accuracy: 0.2719 - loss: 2.1564 - val_accuracy: 0.2912 - val_loss: 2.1247\n",
      "Epoch 80/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2728 - loss: 2.1458 - val_accuracy: 0.2839 - val_loss: 2.1265\n",
      "Epoch 81/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 477ms/step - accuracy: 0.2753 - loss: 2.1402 - val_accuracy: 0.2921 - val_loss: 2.1218\n",
      "Epoch 82/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2728 - loss: 2.1487 - val_accuracy: 0.3012 - val_loss: 2.1309\n",
      "Epoch 83/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 469ms/step - accuracy: 0.2785 - loss: 2.1382 - val_accuracy: 0.2684 - val_loss: 2.1375\n",
      "Epoch 84/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2774 - loss: 2.1427 - val_accuracy: 0.2903 - val_loss: 2.1225\n",
      "Epoch 85/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2749 - loss: 2.1529 - val_accuracy: 0.3039 - val_loss: 2.1236\n",
      "Epoch 86/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2749 - loss: 2.1454 - val_accuracy: 0.2857 - val_loss: 2.1171\n",
      "Epoch 87/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 470ms/step - accuracy: 0.2664 - loss: 2.1468 - val_accuracy: 0.3021 - val_loss: 2.1098\n",
      "Epoch 88/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2808 - loss: 2.1279 - val_accuracy: 0.2848 - val_loss: 2.1217\n",
      "Epoch 89/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2796 - loss: 2.1342 - val_accuracy: 0.3103 - val_loss: 2.1136\n",
      "Epoch 90/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2790 - loss: 2.1358 - val_accuracy: 0.2903 - val_loss: 2.1201\n",
      "Epoch 91/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2712 - loss: 2.1432 - val_accuracy: 0.2912 - val_loss: 2.1241\n",
      "Epoch 92/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2705 - loss: 2.1444 - val_accuracy: 0.3039 - val_loss: 2.1132\n",
      "Epoch 93/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2701 - loss: 2.1366 - val_accuracy: 0.3085 - val_loss: 2.1150\n",
      "Epoch 94/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2762 - loss: 2.1220 - val_accuracy: 0.3103 - val_loss: 2.1065\n",
      "Epoch 95/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2790 - loss: 2.1304 - val_accuracy: 0.3203 - val_loss: 2.1145\n",
      "Epoch 96/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 488ms/step - accuracy: 0.2744 - loss: 2.1371 - val_accuracy: 0.3212 - val_loss: 2.1135\n",
      "Epoch 97/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2787 - loss: 2.1363 - val_accuracy: 0.3057 - val_loss: 2.1130\n",
      "Epoch 98/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2774 - loss: 2.1334 - val_accuracy: 0.3076 - val_loss: 2.1054\n",
      "Epoch 99/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2801 - loss: 2.1424 - val_accuracy: 0.2966 - val_loss: 2.1145\n",
      "Epoch 100/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2751 - loss: 2.1264 - val_accuracy: 0.2821 - val_loss: 2.1179\n",
      "Epoch 101/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2776 - loss: 2.1279 - val_accuracy: 0.2930 - val_loss: 2.1053\n",
      "Epoch 102/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2849 - loss: 2.1268 - val_accuracy: 0.3112 - val_loss: 2.1084\n",
      "Epoch 103/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2833 - loss: 2.1367 - val_accuracy: 0.2921 - val_loss: 2.1175\n",
      "Epoch 104/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2835 - loss: 2.1147 - val_accuracy: 0.3103 - val_loss: 2.1049\n",
      "Epoch 105/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2840 - loss: 2.1238 - val_accuracy: 0.3076 - val_loss: 2.1044\n",
      "Epoch 106/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2878 - loss: 2.1211 - val_accuracy: 0.2994 - val_loss: 2.1078\n",
      "Epoch 107/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 467ms/step - accuracy: 0.2903 - loss: 2.1169 - val_accuracy: 0.3121 - val_loss: 2.1013\n",
      "Epoch 108/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2796 - loss: 2.1150 - val_accuracy: 0.3030 - val_loss: 2.1021\n",
      "Epoch 109/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2899 - loss: 2.1119 - val_accuracy: 0.2894 - val_loss: 2.1205\n",
      "Epoch 110/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 471ms/step - accuracy: 0.2981 - loss: 2.1044 - val_accuracy: 0.3076 - val_loss: 2.0904\n",
      "Epoch 111/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2922 - loss: 2.1100 - val_accuracy: 0.2930 - val_loss: 2.1093\n",
      "Epoch 112/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2901 - loss: 2.1239 - val_accuracy: 0.3094 - val_loss: 2.0976\n",
      "Epoch 113/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2856 - loss: 2.1181 - val_accuracy: 0.3139 - val_loss: 2.0902\n",
      "Epoch 114/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2896 - loss: 2.1159 - val_accuracy: 0.3012 - val_loss: 2.0928\n",
      "Epoch 115/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2958 - loss: 2.1109 - val_accuracy: 0.3121 - val_loss: 2.0874\n",
      "Epoch 116/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2835 - loss: 2.1163 - val_accuracy: 0.3103 - val_loss: 2.0914\n",
      "Epoch 117/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2924 - loss: 2.1018 - val_accuracy: 0.3157 - val_loss: 2.0926\n",
      "Epoch 118/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2762 - loss: 2.1275 - val_accuracy: 0.3321 - val_loss: 2.0816\n",
      "Epoch 119/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2833 - loss: 2.1208 - val_accuracy: 0.3148 - val_loss: 2.0883\n",
      "Epoch 120/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 467ms/step - accuracy: 0.2856 - loss: 2.1160 - val_accuracy: 0.2866 - val_loss: 2.1176\n",
      "Epoch 121/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2903 - loss: 2.1003 - val_accuracy: 0.3048 - val_loss: 2.0918\n",
      "Epoch 122/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2885 - loss: 2.1078 - val_accuracy: 0.3157 - val_loss: 2.0932\n",
      "Epoch 123/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2833 - loss: 2.1159 - val_accuracy: 0.3103 - val_loss: 2.0909\n",
      "Epoch 124/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2846 - loss: 2.1073 - val_accuracy: 0.3057 - val_loss: 2.1016\n",
      "Epoch 125/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2903 - loss: 2.1082 - val_accuracy: 0.3103 - val_loss: 2.0959\n",
      "Epoch 126/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 467ms/step - accuracy: 0.2765 - loss: 2.1154 - val_accuracy: 0.3057 - val_loss: 2.0842\n",
      "Epoch 127/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2835 - loss: 2.1039 - val_accuracy: 0.3157 - val_loss: 2.0821\n",
      "Epoch 128/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2862 - loss: 2.1066 - val_accuracy: 0.2985 - val_loss: 2.0869\n",
      "Epoch 129/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2926 - loss: 2.1025 - val_accuracy: 0.3076 - val_loss: 2.1019\n",
      "Epoch 130/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.3010 - loss: 2.1049 - val_accuracy: 0.3103 - val_loss: 2.0800\n",
      "Epoch 131/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 467ms/step - accuracy: 0.2917 - loss: 2.1018 - val_accuracy: 0.2793 - val_loss: 2.1099\n",
      "Epoch 132/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2856 - loss: 2.0995 - val_accuracy: 0.3121 - val_loss: 2.0923\n",
      "Epoch 133/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2867 - loss: 2.1027 - val_accuracy: 0.3003 - val_loss: 2.0923\n",
      "Epoch 134/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2956 - loss: 2.0992 - val_accuracy: 0.3012 - val_loss: 2.0782\n",
      "Epoch 135/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2894 - loss: 2.1064 - val_accuracy: 0.3066 - val_loss: 2.0963\n",
      "Epoch 136/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2890 - loss: 2.1027 - val_accuracy: 0.3094 - val_loss: 2.0849\n",
      "Epoch 137/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2901 - loss: 2.0957 - val_accuracy: 0.3176 - val_loss: 2.0820\n",
      "Epoch 138/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 467ms/step - accuracy: 0.2917 - loss: 2.1058 - val_accuracy: 0.3157 - val_loss: 2.0868\n",
      "Epoch 139/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 466ms/step - accuracy: 0.2899 - loss: 2.0937 - val_accuracy: 0.3103 - val_loss: 2.0891\n",
      "Epoch 140/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2851 - loss: 2.1000 - val_accuracy: 0.3130 - val_loss: 2.0838\n",
      "Epoch 141/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2906 - loss: 2.1021 - val_accuracy: 0.2966 - val_loss: 2.0896\n",
      "Epoch 142/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2824 - loss: 2.1128 - val_accuracy: 0.2894 - val_loss: 2.0846\n",
      "Epoch 143/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.3008 - loss: 2.0971 - val_accuracy: 0.3276 - val_loss: 2.0773\n",
      "Epoch 144/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 478ms/step - accuracy: 0.2953 - loss: 2.0976 - val_accuracy: 0.3185 - val_loss: 2.0721\n",
      "Epoch 145/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2910 - loss: 2.1045 - val_accuracy: 0.3248 - val_loss: 2.0771\n",
      "Epoch 146/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2919 - loss: 2.0960 - val_accuracy: 0.3094 - val_loss: 2.0889\n",
      "Epoch 147/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 469ms/step - accuracy: 0.2965 - loss: 2.0804 - val_accuracy: 0.3030 - val_loss: 2.0823\n",
      "Epoch 148/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2933 - loss: 2.1025 - val_accuracy: 0.3176 - val_loss: 2.0842\n",
      "Epoch 149/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2953 - loss: 2.0923 - val_accuracy: 0.3103 - val_loss: 2.0736\n",
      "Epoch 150/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2942 - loss: 2.0893 - val_accuracy: 0.3076 - val_loss: 2.0747\n",
      "Epoch 151/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2940 - loss: 2.1005 - val_accuracy: 0.3148 - val_loss: 2.0755\n",
      "Epoch 152/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 473ms/step - accuracy: 0.2933 - loss: 2.0902 - val_accuracy: 0.3267 - val_loss: 2.0669\n",
      "Epoch 153/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2885 - loss: 2.0940 - val_accuracy: 0.3176 - val_loss: 2.0664\n",
      "Epoch 154/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2983 - loss: 2.0965 - val_accuracy: 0.3066 - val_loss: 2.0845\n",
      "Epoch 155/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.3017 - loss: 2.0791 - val_accuracy: 0.3212 - val_loss: 2.0696\n",
      "Epoch 156/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2937 - loss: 2.0953 - val_accuracy: 0.3212 - val_loss: 2.0835\n",
      "Epoch 157/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2935 - loss: 2.0994 - val_accuracy: 0.3167 - val_loss: 2.0759\n",
      "Epoch 158/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2890 - loss: 2.0908 - val_accuracy: 0.3021 - val_loss: 2.0861\n",
      "Epoch 159/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2981 - loss: 2.0926 - val_accuracy: 0.3148 - val_loss: 2.0681\n",
      "Epoch 160/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.3019 - loss: 2.0901 - val_accuracy: 0.3176 - val_loss: 2.0729\n",
      "Epoch 161/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 472ms/step - accuracy: 0.2949 - loss: 2.0918 - val_accuracy: 0.2985 - val_loss: 2.0836\n",
      "Epoch 162/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.3058 - loss: 2.0810 - val_accuracy: 0.3139 - val_loss: 2.0718\n",
      "Epoch 163/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2928 - loss: 2.0872 - val_accuracy: 0.3294 - val_loss: 2.0727\n",
      "Epoch 164/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2976 - loss: 2.0820 - val_accuracy: 0.3021 - val_loss: 2.0802\n",
      "Epoch 165/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 472ms/step - accuracy: 0.3028 - loss: 2.0743 - val_accuracy: 0.3012 - val_loss: 2.0825\n",
      "Epoch 166/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 473ms/step - accuracy: 0.2985 - loss: 2.0835 - val_accuracy: 0.3267 - val_loss: 2.0653\n",
      "Epoch 167/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 472ms/step - accuracy: 0.3026 - loss: 2.0754 - val_accuracy: 0.3221 - val_loss: 2.0547\n",
      "Epoch 168/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2937 - loss: 2.0861 - val_accuracy: 0.3230 - val_loss: 2.0768\n",
      "Epoch 169/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 499ms/step - accuracy: 0.2997 - loss: 2.0863 - val_accuracy: 0.3148 - val_loss: 2.0626\n",
      "Epoch 170/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 499ms/step - accuracy: 0.2997 - loss: 2.0752 - val_accuracy: 0.3103 - val_loss: 2.0828\n",
      "Epoch 171/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2983 - loss: 2.0949 - val_accuracy: 0.3212 - val_loss: 2.0582\n",
      "Epoch 172/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 472ms/step - accuracy: 0.2969 - loss: 2.0961 - val_accuracy: 0.3057 - val_loss: 2.0740\n",
      "Epoch 173/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2958 - loss: 2.0797 - val_accuracy: 0.3258 - val_loss: 2.0660\n",
      "Epoch 174/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.3033 - loss: 2.0778 - val_accuracy: 0.3167 - val_loss: 2.0667\n",
      "Epoch 175/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.3026 - loss: 2.0846 - val_accuracy: 0.3094 - val_loss: 2.0749\n",
      "Epoch 176/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.3083 - loss: 2.0712 - val_accuracy: 0.3148 - val_loss: 2.0619\n",
      "Epoch 177/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.3078 - loss: 2.0714 - val_accuracy: 0.3157 - val_loss: 2.0586\n",
      "Epoch 178/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.2860 - loss: 2.0977 - val_accuracy: 0.3176 - val_loss: 2.0768\n",
      "Epoch 179/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2983 - loss: 2.0800 - val_accuracy: 0.3312 - val_loss: 2.0600\n",
      "Epoch 180/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.3031 - loss: 2.0758 - val_accuracy: 0.3130 - val_loss: 2.0639\n",
      "Epoch 181/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2928 - loss: 2.0733 - val_accuracy: 0.3157 - val_loss: 2.0881\n",
      "Epoch 182/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.3035 - loss: 2.0781 - val_accuracy: 0.3176 - val_loss: 2.0606\n",
      "Epoch 183/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2983 - loss: 2.0784 - val_accuracy: 0.3321 - val_loss: 2.0658\n",
      "Epoch 184/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.2962 - loss: 2.0839 - val_accuracy: 0.3139 - val_loss: 2.0632\n",
      "Epoch 185/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.3056 - loss: 2.0691 - val_accuracy: 0.3194 - val_loss: 2.0534\n",
      "Epoch 186/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.3078 - loss: 2.0685 - val_accuracy: 0.3157 - val_loss: 2.0624\n",
      "Epoch 187/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2917 - loss: 2.0791 - val_accuracy: 0.3230 - val_loss: 2.0602\n",
      "Epoch 188/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.3042 - loss: 2.0687 - val_accuracy: 0.3085 - val_loss: 2.0804\n",
      "Epoch 189/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.3024 - loss: 2.0616 - val_accuracy: 0.3148 - val_loss: 2.0610\n",
      "Epoch 190/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.3076 - loss: 2.0789 - val_accuracy: 0.3194 - val_loss: 2.0542\n",
      "Epoch 191/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 469ms/step - accuracy: 0.2958 - loss: 2.0801 - val_accuracy: 0.3157 - val_loss: 2.0635\n",
      "Epoch 192/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 472ms/step - accuracy: 0.3074 - loss: 2.0753 - val_accuracy: 0.3303 - val_loss: 2.0583\n",
      "Epoch 193/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.2974 - loss: 2.0746 - val_accuracy: 0.3303 - val_loss: 2.0526\n",
      "Epoch 194/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 471ms/step - accuracy: 0.3067 - loss: 2.0687 - val_accuracy: 0.3294 - val_loss: 2.0585\n",
      "Epoch 195/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 473ms/step - accuracy: 0.3099 - loss: 2.0588 - val_accuracy: 0.3258 - val_loss: 2.0529\n",
      "Epoch 196/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 469ms/step - accuracy: 0.3038 - loss: 2.0725 - val_accuracy: 0.3248 - val_loss: 2.0584\n",
      "Epoch 197/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 468ms/step - accuracy: 0.2912 - loss: 2.0843 - val_accuracy: 0.3076 - val_loss: 2.0651\n",
      "Epoch 198/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.3001 - loss: 2.0714 - val_accuracy: 0.3258 - val_loss: 2.0541\n",
      "Epoch 199/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 470ms/step - accuracy: 0.3090 - loss: 2.0696 - val_accuracy: 0.3276 - val_loss: 2.0579\n",
      "Epoch 200/200\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 479ms/step - accuracy: 0.3049 - loss: 2.0563 - val_accuracy: 0.3267 - val_loss: 2.0609\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 338ms/step - accuracy: 0.3267 - loss: 2.0609\n",
      "Test Accuracy: 32.67%\n",
      "Test Loss: 2.0609\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (300, 300)\n",
    "BATCH = 24\n",
    "NUM_CLASSES = 12\n",
    "\n",
    "train_data_gener = ImageDataGenerator(rescale = 1./255, rotation_range = 20, \n",
    "                                width_shift_range = 0.1, height_shift_range = 0.1,\n",
    "                                zoom_range = 0.2, brightness_range = [0.5, 2],\n",
    "                                shear_range = 0.2, horizontal_flip = True)\n",
    "test_data_gener = ImageDataGenerator(rescale = 1./255)\n",
    "train_data = train_data_gener.flow_from_directory('train', target_size = IMG_SIZE, \n",
    "                                                  batch_size = BATCH, class_mode = 'categorical',\n",
    "                                                  shuffle = True)\n",
    "test_data = test_data_gener.flow_from_directory('test', target_size = IMG_SIZE, \n",
    "                                                  batch_size = BATCH, class_mode = 'categorical',\n",
    "                                                  shuffle = True)\n",
    "\n",
    "base_model = EfficientNetV2S(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE,3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_data, validation_data=test_data, epochs=200)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d07a997-c383-4731-b5ba-bc46fd6335f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
